{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeee441e",
   "metadata": {},
   "source": [
    "# This script is the first phase of the Steam Data Pipeline.\n",
    "\n",
    "Its purpose is to:\n",
    "1. Fetch a master list of all games from the SteamSpy API.\n",
    "2. Process the data for each game, performing basic cleaning and feature engineering.\n",
    "3. Store the cleaned data in a MongoDB collection, ensuring no duplicates are created.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba1be9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pymongo import MongoClient\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Imports the custom logger\n",
    "from utility.log_debug import logging\n",
    "from pymongo.operations import UpdateOne\n",
    "import time \n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf3e78b",
   "metadata": {},
   "source": [
    "# Configuration setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25a0f802",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-19 15:52:00,993 - INFO - MongoDB connection successful.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MONGO_URI = os.environ.get('MONGO_URI')\n",
    "\n",
    "client = MongoClient(MONGO_URI)\n",
    "\n",
    "DB_NAME = \"steam_games\"\n",
    "GAME_COLLECTION = \"game_infos\"\n",
    "REVIEW_COLLECTION = \"reviews\"\n",
    "\n",
    "MAX_WORKERS = 15\n",
    "\n",
    "game_collection = client[DB_NAME][GAME_COLLECTION]\n",
    "review_collection = client[DB_NAME][REVIEW_COLLECTION]\n",
    "\n",
    "STEAMSPY_API_URL = \"https://steamspy.com/api.php?request=all\"\n",
    "\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    logging.info(\"MongoDB connection successful.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"UNABLE to connect to MongoDB. Please check your MONGO_URI. Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef184cc0",
   "metadata": {},
   "source": [
    "#  DATA FETCHING FUNCTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a4481ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_steamspy_game(STEAMSPY_API_URL):\n",
    "    \"\"\"Fetches the complete game dataset from the SteamSpy API.\"\"\"\n",
    "    try:\n",
    "        logging.info(\"Attempting to retrieve data from SteamSpy...\")\n",
    "        response = requests.get(STEAMSPY_API_URL)\n",
    "        # This will automatically raise an error if the API returns a bad status (e.g., 404, 503).\n",
    "        response.raise_for_status()\n",
    "        logging.info(\"Retrieve data from SteamSpy SUCCESSFULLY!\")\n",
    "        return response.json()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error! Unable to retrieve data from SteamSpy: {e}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5003f25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-19 15:52:01,016 - INFO - Attempting to retrieve data from SteamSpy...\n",
      "2025-10-19 15:52:01,378 - INFO - Retrieve data from SteamSpy SUCCESSFULLY!\n",
      "2025-10-19 15:52:01,384 - INFO - Retrieved data for 1000 games. Starting ingestion process...\n",
      "Processing game data: 100%|██████████| 1000/1000 [00:19<00:00, 50.58it/s]\n",
      "2025-10-19 15:52:21,166 - INFO - --- COMPLETE LOADING GAME INFO ---\n"
     ]
    }
   ],
   "source": [
    "all_games_data = get_steamspy_game(STEAMSPY_API_URL)\n",
    "\n",
    "\n",
    "if all_games_data:\n",
    "    logging.info(f\"Retrieved data for {len(all_games_data)} games. Starting ingestion process...\")\n",
    "\n",
    "    for app_info, info_dict in tqdm(all_games_data.items(), desc=\"Processing game data\"):\n",
    "        try:\n",
    "            app_id = int(app_info)\n",
    "            # Safely parse the 'owners' string (e.g., \"20,000 .. 50,000\") into numbers.\n",
    "            min_owner = 0  \n",
    "            max_owner = 0  \n",
    "            owner_string = info_dict.get(\"owners\")\n",
    "            if owner_string:\n",
    "\n",
    "                owner_numbers = re.findall(r'\\d+', owner_string.replace(\",\", \"\"))\n",
    "\n",
    "                if len(owner_numbers) >= 2:\n",
    "                    min_owner = int(owner_numbers[0])\n",
    "                    max_owner = int(owner_numbers[1])\n",
    "                elif len(owner_numbers) == 1:\n",
    "                    # Handles cases where only one number is provided (e.g., \"5,000\").\n",
    "                    min_owner = int(owner_numbers[0])\n",
    "                    max_owner = int(owner_numbers[0])\n",
    "\n",
    "\n",
    "            # ---  Create the final document for MongoDB ---\n",
    "            game_document = {\n",
    "                \"_id\": app_id,  # Use the app_id as the unique primary key.\n",
    "                \"name\": info_dict.get(\"name\"),\n",
    "                \"developer\": info_dict.get(\"developer\"),\n",
    "                \"publisher\": info_dict.get(\"publisher\"),\n",
    "                \"score_rank\": info_dict.get(\"score_rank\"),\n",
    "                \"positive_reviews\": info_dict.get(\"positive\"),\n",
    "                \"negative_reviews\": info_dict.get(\"negative\"),\n",
    "                \"user_score\": info_dict.get(\"userscore\"),\n",
    "                \"min_owners_estimated\": min_owner, # Use the cleaned integer value.\n",
    "                \"max_owners_estimated\": max_owner, # Use the cleaned integer value.\n",
    "                \"avg_playtime_forever\": info_dict.get(\"average_forever\"),\n",
    "                \"avg_playtime_2weeks\": info_dict.get(\"average_2weeks\"),\n",
    "                \"price_cents\": info_dict.get(\"price\"),\n",
    "                \"initial_price_cents\": info_dict.get(\"initialprice\"),\n",
    "                \"discount_percent\": info_dict.get(\"discount\"),\n",
    "                \"concurrent_users\": info_dict.get(\"ccu\"),\n",
    "            }\n",
    "            \n",
    "            filter_query = {\"_id\": app_id}\n",
    "            update_operation = {\"$set\": game_document}\n",
    "           \n",
    "            game_collection.update_one(filter_query, update_operation, upsert=True)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Unable to process {app_id}: {info_dict.get('name')}. Error: {e}\")\n",
    "            continue\n",
    "\n",
    "\n",
    "logging.info(\"--- COMPLETE LOADING GAME INFO ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f618951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_steam_reviews(appid, num_reviews_target=1000, months_to_fetch=3):\n",
    "    \"\"\"\n",
    "    Fetches up to a target number of reviews from the last N months.\n",
    "    \"\"\"\n",
    "\n",
    "    reviews_collected = []\n",
    "    cursor = '*'\n",
    "    \n",
    "    # Calculate the cutoff date. We will stop when reviews are older than this.\n",
    "    cutoff_date = datetime.now() - timedelta(days=months_to_fetch * 30)\n",
    "\n",
    "    while len(reviews_collected) < num_reviews_target:\n",
    "        try:\n",
    "            url = f\"https://store.steampowered.com/appreviews/{appid}?json=1&cursor={cursor}&language=english&filter=all&num_per_page=100\"\n",
    "            \n",
    "            response = requests.get(url, timeout=15)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            if not data or data.get(\"success\") != 1 or not data.get(\"reviews\"):\n",
    "                break\n",
    "            \n",
    "            batch_reviews = data.get(\"reviews\", [])\n",
    "            for review in batch_reviews:\n",
    "                review_date = datetime.fromtimestamp(review['timestamp_created'])\n",
    "                if review_date >= cutoff_date:\n",
    "                    review['app_id'] = appid\n",
    "                    reviews_collected.append(review)\n",
    "            \n",
    "            if batch_reviews:\n",
    "                last_review_date = datetime.fromtimestamp(batch_reviews[-1]['timestamp_created'])\n",
    "                if last_review_date < cutoff_date:\n",
    "                    break\n",
    "\n",
    "            next_cursor = data.get(\"cursor\")\n",
    "            if not next_cursor or next_cursor == cursor:\n",
    "                break\n",
    "            \n",
    "            cursor = next_cursor\n",
    "            time.sleep(1)\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logging.error(f\"HTTP Error while fetching reviews for AppID {appid}: {e}\")\n",
    "            break\n",
    "    return reviews_collected\n",
    "\n",
    "def process_review(app_id):\n",
    "    try:\n",
    "        reviews = fetch_steam_reviews(app_id)\n",
    "        if reviews:\n",
    "            bulk_op = []\n",
    "            for single_review in reviews:\n",
    "                query = {\"recommendationid\" : single_review[\"recommendationid\"]}\n",
    "                operation = {\"$set\": single_review}\n",
    "                bulk_op.append(UpdateOne(query, operation, upsert= True))\n",
    "\n",
    "            if bulk_op:\n",
    "                review_collection.bulk_write(bulk_op)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"ERROR, Unable to load {single_review} : {e}\")\n",
    "    return \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80709359",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-19 15:52:21,190 - INFO - --- BEGIN TO COLLECT GAME REVIEWS ---\n",
      "Processing...: 100%|██████████| 1000/1000 [09:20<00:00,  1.79it/s]\n",
      "2025-10-19 16:01:41,400 - INFO - --- COMPLETE LOADING GAME REVIEWS ---\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"--- BEGIN TO COLLECT GAME REVIEWS ---\")\n",
    "app_ids = []\n",
    "\n",
    "for app_info, info_dict in all_games_data.items():\n",
    "        app_ids.append(int(app_info))\n",
    "\n",
    "with ThreadPoolExecutor(max_workers= MAX_WORKERS) as executor:\n",
    "    list(tqdm(executor.map(process_review, app_ids), total=len(app_ids), desc= \"Processing...\"))\n",
    "    \n",
    "logging.info(\"--- COMPLETE LOADING GAME REVIEWS ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
